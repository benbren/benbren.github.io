<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Linear Regression | Ben Brennan</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Linear Regression" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Hi, I’m Ben. This is my website/blog. Views are my own. Thanks for looking." />
<meta property="og:description" content="Hi, I’m Ben. This is my website/blog. Views are my own. Thanks for looking." />
<link rel="canonical" href="http://localhost:4000/2018/03/10/linear-regression.html" />
<meta property="og:url" content="http://localhost:4000/2018/03/10/linear-regression.html" />
<meta property="og:site_name" content="Ben Brennan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-03-10T22:00:00-05:00" />
<script type="application/ld+json">
{"description":"Hi, I’m Ben. This is my website/blog. Views are my own. Thanks for looking.","headline":"Linear Regression","@type":"BlogPosting","url":"http://localhost:4000/2018/03/10/linear-regression.html","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/03/10/linear-regression.html"},"dateModified":"2018-03-10T22:00:00-05:00","datePublished":"2018-03-10T22:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Ben Brennan" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Ben Brennan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/">Blog</a><a class="page-link" href="/cv/">CV</a><a class="page-link" href="/donate/">Donate</a><a class="page-link" href="/projects/">Projects</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Linear Regression</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-03-10T22:00:00-05:00" itemprop="datePublished">Mar 10, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p>Linear Regression… the bread and butter of applied statistics.</p>

<p>At one point or another, you have encountered linear regression. Did you read a statistic in the paper this morning? Was that statistic not a percent? Does anybody read the paper anymore?… Anyways, that number was probably derived via running a regression.</p>

<p>A linear regression is used to describe an association (NOT A CAUSAL THING) between one (continuous) response variable, <script type="math/tex">Y</script> and a vector of (continuous or not, whatever) explanatory variables <script type="math/tex">\mathbf{X}</script>. Why is it called linear regression? Well, remember from algebra that a line can be described by</p>

<script type="math/tex; mode=display">y = mx + b</script>

<p>where <script type="math/tex">x</script> is the independent (explanatory) variable and <script type="math/tex">y</script> is the dependent (response) variable. We assume there is a number <script type="math/tex">m</script>, the slope, that describes the relationship here. Essentially, we are saying the same thing with linear regression. We want to find the best <script type="math/tex">\beta_ 0</script> and <script type="math/tex">\beta_1</script> such that the formula</p>

<script type="math/tex; mode=display">Y_i = \beta_0 + \beta_1*X_i + \epsilon_i</script>

<p>is the best fit given our data. It doesn’t matter if <script type="math/tex">X</script> is linear, quadratic, exponential.. only that the relationship is linear in the <script type="math/tex">\beta</script> parameters. <script type="math/tex">\epsilon</script> is an error term for every <script type="math/tex">i</script>  observation. So the problem is really trying to find <script type="math/tex">\beta_0</script> and <script type="math/tex">\beta_1</script> such that <script type="math/tex">\epsilon</script> is minimum overall, i.e. taking into account each observation. The math behind linear regression is all about how we best do that. For this post, we will only explore simple linear regression where we have one explanatory variable. This need not need be the case, and we will cover that another time - but it involves some linear algebra and is a little more involved. The rest of this post assumes some knowledge of statistics, just at a basic level like expected values and distributions.</p>

<p>So, we have this model</p>

<script type="math/tex; mode=display">Y_i = \beta_0 + \beta_1*X_i + \epsilon_i</script>

<p>where <script type="math/tex">Y_i</script> is the response variable, <script type="math/tex">\beta_0</script> is the intercept (fixed), <script type="math/tex">\beta_1</script> is the slope (fixed), <script type="math/tex">X_i</script> is a covariate (fixed) and <script type="math/tex">\epsilon</script> is the error term, which is random and unobservable. As always, we need some assumptions in order to make this workable.. We assume that the errors are normally distributed and unrelated… that is,</p>

<ol>
  <li>
    <script type="math/tex; mode=display">\epsilon_i \sim N(0,\sigma^2)</script>
  </li>
  <li>
    <script type="math/tex; mode=display">E[\epsilon_i\epsilon_j] = 0</script>
  </li>
</ol>

<p>These assumptions lead us to some key implicit assumptions of linear regression. <em>Linearity</em>,  <em>constant variance</em>, <em>independence</em> and <em>normally distributed</em>. That is,</p>

<ol>
  <li>
    <script type="math/tex; mode=display">E[Y_i \vert X_i ] = \beta_0 + \beta_1X_i</script>
  </li>
  <li>
    <script type="math/tex; mode=display">\sigma_i^2 =  V[Y_i \vert X_i] = \sigma^2</script>
  </li>
  <li>
    <script type="math/tex; mode=display">Y_i \perp Y_j, i \neq j</script>
  </li>
  <li>
    <script type="math/tex; mode=display">Y_i \sim N(\beta_0 + \beta_1X_i,\sigma^2)</script>
  </li>
</ol>

<p>We treat the covariates as fixed, but sometimes they aren’t.  For instance, there could be measurement error in the covariates. Really, the goal is to keep that randomness small.</p>

<p>Let’s talk about <script type="math/tex">\beta_0</script> and <script type="math/tex">\beta_1</script>. How should we interpret them? Well, they are part of a linear relationship. We are  going to estimate them such that we fit a line to the data that should give us the expected value of the response given some input parameters.  That is,</p>

<script type="math/tex; mode=display">E[ Y_i | X_i ] = \hat{\beta_0} + \hat{\beta_1}X_i</script>

<p>The little hat things mean they are estimated, not the true parameters… more on that later. So, <script type="math/tex">\hat{\beta_0}</script> is the average value of <script type="math/tex">Y</script>  when <script type="math/tex">X = 0</script>. Furthermore, <script type="math/tex">\hat{\beta_1}</script> is the average change in <script type="math/tex">Y</script> for a unit increase in <script type="math/tex">X</script>. In general, it is best to not extrapolate beyond what your limits for <script type="math/tex">X</script> are. If your covariate is age, and you only have observations for people aged 15 - 30, don’t make the assumption that the model works for a 90-year-old… please.</p>

<p>Okay! Now to the fun stuff… math. We wanna estimate the parameters here. How do we do that? Calculus. :)</p>

<p>First, we need to define best. What is the <em>best</em> fit? That’s arbitrary, as there are many ways to do this. We are going to do it via ordinary least squares, or OLS, which is the default way that any linear regression is fit. What this means is that we want to minimize the <strong>Sum of Squared Errors (SSE)</strong>, or, in math,</p>

<script type="math/tex; mode=display">\sum_{i=1}^{n} \hat{\epsilon_i}^2</script>

<p>So, we need a definition of <script type="math/tex">\hat{\epsilon_i}</script>, Well, it is just <script type="math/tex">Y_i - \hat{Y_i}</script> or, even better, <script type="math/tex">Y_i - (\hat{\beta_0} + \hat{\beta_1}X_i)</script> , since that is how we are guessing our reponse variable. This is good because now we have written <script type="math/tex">\hat{\epsilon_i}</script> as a function of <script type="math/tex">\hat{\beta_0}</script> and <script type="math/tex">\hat{\beta_1}</script>, which are our tuneable parameters. Now we will need a little bit of calculus. This function will reach a critical value when</p>

<script type="math/tex; mode=display">\textbf{\(*\)} \frac{\partial SSE}{\partial \beta_0} = 0</script>

<p>and</p>

<script type="math/tex; mode=display">\textbf{\(**\)} \frac{\partial SSE}{\partial \beta_1} = 0</script>

<p>Remember? ;)</p>

<p>Let’s solve (*) first.</p>

<script type="math/tex; mode=display">\frac{\partial SSE}{\partial \beta_0} = 0</script>

<script type="math/tex; mode=display">\implies -2 \sum_{i=1}^{n}(Y_i - \hat{\beta_0} -\hat{\beta_1}X_i) = 0</script>

<script type="math/tex; mode=display">\implies \sum_{i=1}^{n}Y_i  - \hat{\beta_1}\sum_{i=1}^{n}X_i= n\hat{\beta_0}</script>

<script type="math/tex; mode=display">\implies \hat{\beta_0} = \bar{Y} - \hat{\beta_1}\bar{X}</script>

<p>So, if we know <script type="math/tex">\hat{\beta_1}</script>, we can estimate <script type="math/tex">\hat{\beta_0}</script> . Now, looking at (**) and subbing in this result,</p>

<script type="math/tex; mode=display">\frac{\partial SSE}{\partial \beta_1} = 0</script>

<script type="math/tex; mode=display">\implies -2 \sum_{i=1}^{n}X_i (Y_i - \hat{\beta_0} -\hat{\beta_1}X_i) = 0</script>

<script type="math/tex; mode=display">\implies -2 \sum_{i=1}^{n}X_i (Y_i -\bar{Y} +\hat{\beta_1}\bar{X} -\hat{\beta_1}X_i) = 0</script>

<script type="math/tex; mode=display">\implies \sum_{i=1}^{n}X_i(Y_i - \bar{Y}) = \hat{\beta_1} \sum_{i=1}^{n}X_i(X_i - \bar{X})</script>

<script type="math/tex; mode=display">\implies \hat{\beta_1} = \frac{SSXY}{SSX}</script>

<p>where <script type="math/tex">SSXY = \sum_{i=1}^{n}X_i(Y_i - \bar{Y})</script> and <script type="math/tex">SSX =  \sum_{i=1}^{n}X_i(X_i - \bar{X})</script></p>

<p>Awesome! Now, given a vector of covariates and a vector of responses, you can estimate both paramaters quite easily! We didn’t really need to do this though. It is good for understanding… but we didn’t need to do the calculus, we have <code class="highlighter-rouge">R</code> to do this!</p>


  </div><a class="u-url" href="/2018/03/10/linear-regression.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ben Brennan</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ben Brennan</li><li><a class="u-email" href="mailto:brennben@umich.edu">brennben@umich.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/benbren"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">benbren</span></a></li><li><a href="https://instagram.com/benjuum"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#instagram"></use></svg> <span class="username">benjuum</span></a></li><li><a href="https://www.linkedin.com/in/ben-brenn"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">ben-brenn</span></a></li><li><a href="https://www.twitter.com/benbrenn"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">benbrenn</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Hi, I&#39;m Ben. This is my website/blog. Views are my own. Thanks for looking.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
